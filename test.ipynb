{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:1234/synthesize\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = {\n",
    "  \"language\": \"KR\",\n",
    "  \"text\": \"안녕하세요~ 방가웡\",\n",
    "  \"speed\": 1.5,\n",
    "\n",
    "}\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "# 오디오 데이터를 파일로 저장\n",
    "with open(\"synthesized_audio.wav\", \"wb\") as f:\n",
    "    f.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC_1M\\anaconda3\\envs\\py310\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "model = whisper.load_model(\"base\")\n",
    "# 모델이 정상적으로 로드되면 설치가 완료된 것입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 Microsoft Sound Mapper - Input, MME (2 in, 0 out)\n",
      ">  1 마이크(Usb Audio Device), MME (1 in, 0 out)\n",
      "   2 Microsoft Sound Mapper - Output, MME (0 in, 2 out)\n",
      "<  3 스피커(Realtek High Definition Aud, MME (0 in, 8 out)\n",
      "   4 LG TV(NVIDIA High Definition Au, MME (0 in, 2 out)\n",
      "   5 LG FULL HD(NVIDIA High Definiti, MME (0 in, 2 out)\n",
      "   6 주 사운드 캡처 드라이버, Windows DirectSound (2 in, 0 out)\n",
      "   7 마이크(Usb Audio Device), Windows DirectSound (1 in, 0 out)\n",
      "   8 주 사운드 드라이버, Windows DirectSound (0 in, 2 out)\n",
      "   9 스피커(Realtek High Definition Audio), Windows DirectSound (0 in, 8 out)\n",
      "  10 LG TV(NVIDIA High Definition Audio), Windows DirectSound (0 in, 2 out)\n",
      "  11 LG FULL HD(NVIDIA High Definition Audio), Windows DirectSound (0 in, 2 out)\n",
      "  12 LG TV(NVIDIA High Definition Audio), Windows WASAPI (0 in, 2 out)\n",
      "  13 LG FULL HD(NVIDIA High Definition Audio), Windows WASAPI (0 in, 2 out)\n",
      "  14 스피커(Realtek High Definition Audio), Windows WASAPI (0 in, 2 out)\n",
      "  15 마이크(Usb Audio Device), Windows WASAPI (1 in, 0 out)\n",
      "  16 라인 입력 (Realtek HD Audio Line input), Windows WDM-KS (2 in, 0 out)\n",
      "  17 스테레오 믹스 (Realtek HD Audio Stereo input), Windows WDM-KS (2 in, 0 out)\n",
      "  18 Speakers (Realtek HD Audio output), Windows WDM-KS (0 in, 8 out)\n",
      "  19 마이크 (Realtek HD Audio Mic input), Windows WDM-KS (2 in, 0 out)\n",
      "  20 마이크 (Usb Audio Device), Windows WDM-KS (1 in, 0 out)\n",
      "  21 Output (NVIDIA High Definition Audio), Windows WDM-KS (0 in, 2 out)\n",
      "  22 Output (), Windows WDM-KS (0 in, 2 out)\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "print(sd.query_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PyTorch ===\n",
      "PyTorch 버전: 2.5.1+cu121\n",
      "CUDA 사용 가능: True\n",
      "CUDA 버전: 12.1\n",
      "GPU 이름: NVIDIA GeForce RTX 3060\n",
      "\n",
      "=== PyTorch GPU 테스트 ===\n",
      "PyTorch GPU 연산 완료!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"=== PyTorch ===\")\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "    print(f\"GPU 이름: {torch.cuda.get_device_name(0)}\")\n",
    "# 간단한 GPU 테스트\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\n=== PyTorch GPU 테스트 ===\")\n",
    "    x = torch.rand(1000, 1000).cuda()\n",
    "    y = torch.rand(1000, 1000).cuda()\n",
    "    z = torch.matmul(x, y)\n",
    "    print(\"PyTorch GPU 연산 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TensorFlow ===\n",
      "TensorFlow 버전: 2.10.0\n",
      "GPU 디바이스:\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "=== TensorFlow GPU 테스트 ===\n",
      "TensorFlow GPU 연산 완료!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"\\n=== TensorFlow ===\")\n",
    "print(f\"TensorFlow 버전: {tf.__version__}\")\n",
    "print(\"GPU 디바이스:\")\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"\\n=== TensorFlow GPU 테스트 ===\")\n",
    "    with tf.device('/GPU:0'):\n",
    "        x = tf.random.uniform((1000, 1000))\n",
    "        y = tf.random.uniform((1000, 1000))\n",
    "        z = tf.matmul(x, y)\n",
    "    print(\"TensorFlow GPU 연산 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "AI 응답: 주식 투자 명언 5가지를 소개해드릴게요.\n",
    "\n",
    "1. \"자신의 감정을 믿지 말고, 시장의 감정을 이해하라.\"\n",
    "2. \"확실한 것은 없다, 그러니 항상 리스크 관리에 신경 써라.\"\n",
    "3. \"장기적인 목표를 설정하고 단기적인 변동에 휘둘리지 마라.\"\n",
    "4. \"정보는 돈이다, 끊임없이 공부하고 배우라.\"\n",
    "5. \"주식 투자에서 가장 중요한 것은 인내와 지속적인 노력이다.\"\n",
    "\n",
    "이 명언들이 투자에 도움이 되길 바랍니다!\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sentences = re.split('(?<=[.!?]) +', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAI 응답: 주식 투자 명언 5가지를 소개해드릴게요.\\n\\n1.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greeting.wav 파일이 성공적으로 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def generate_greeting_audio():\n",
    "    tts_url = \"http://127.0.0.1:1234/synthesize\"\n",
    "    tts_headers = {\"Content-Type\": \"application/json\"}\n",
    "    greeting_message = \"안녕하세요. 저는 김비서입니다. 무엇을 도와드릴까요?\"\n",
    "\n",
    "    tts_data = {\n",
    "        \"language\": \"KR\",\n",
    "        \"text\": greeting_message,\n",
    "        \"speed\": 1.5\n",
    "    }\n",
    "\n",
    "    response = requests.post(tts_url, headers=tts_headers, json=tts_data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(\"greeting.wav\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(\"greeting.wav 파일이 성공적으로 생성되었습니다.\")\n",
    "    else:\n",
    "        print(f\"TTS API 오류: {response.status_code}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_greeting_audio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프로그램 시작...\n",
      "SmartAssistant 초기화 시작...\n",
      "Whisper 모델 로딩 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC_1M\\anaconda3\\envs\\py310\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper 모델 로딩 완료\n",
      "SmartAssistant 초기화 완료\n",
      "\n",
      "AI 어시스턴트가 시작되었습니다.\n",
      "AI 응답: 안녕하세요. 저는 지니입니다. 무엇을 도와드릴까요?\n",
      "엔터 키를 눌러 녹음을 시작하세요...\n",
      "\n",
      "프로그램을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import queue\n",
    "import sounddevice as sd\n",
    "import whisper\n",
    "import numpy as np\n",
    "import threading\n",
    "import requests\n",
    "import time\n",
    "import wave\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import soundfile as sf\n",
    "import warnings\n",
    "from collections import deque\n",
    "import pyaudio\n",
    "import keyboard\n",
    "import re\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "# 환경 변수 설정\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 경고 메시지 필터링\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "class SmartAssistant:\n",
    "    def __init__(self):\n",
    "        print(\"SmartAssistant 초기화 시작...\")\n",
    "        try:\n",
    "            # PyAudio 초기화\n",
    "            self.audio = pyaudio.PyAudio()\n",
    "\n",
    "            # 오디오 설정\n",
    "            self.samplerate = 16000\n",
    "            self.channels = 1\n",
    "            self.chunk_size = 1024\n",
    "            self.format = pyaudio.paInt16\n",
    "\n",
    "            # TTS API 설정\n",
    "            self.tts_url = \"http://127.0.0.1:1234/synthesize\"\n",
    "            self.tts_headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "            self.initialize_audio_device()\n",
    "            print(\"Whisper 모델 로딩 중...\")\n",
    "            self.whisper_model = whisper.load_model(\"base\")\n",
    "            print(\"Whisper 모델 로딩 완료\")\n",
    "\n",
    "            # 녹음 상태 관리\n",
    "            self.is_recording = False\n",
    "            self.is_speaking = False\n",
    "            self.recorded_frames = []\n",
    "            self.first_recording = True\n",
    "            \n",
    "            # Thread Pool 초기화\n",
    "            self.executor = ThreadPoolExecutor(max_workers=3)\n",
    "            \n",
    "            # 시작 멘트 설정\n",
    "            self.greeting_message = \"안녕하세요. 저는 지니입니다. 무엇을 도와드릴까요?\"\n",
    "            \n",
    "            print(\"SmartAssistant 초기화 완료\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"초기화 중 오류 발생: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def initialize_audio_device(self):\n",
    "        \"\"\"윈도우용 오디오 장치 초기화 및 설정\"\"\"\n",
    "        try:\n",
    "            print(\"\\n오디오 장치 초기화 시작...\")\n",
    "\n",
    "            # 사용 가능한 모든 오디오 장치 출력\n",
    "            print(\"\\n사용 가능한 입력 장치:\")\n",
    "            for i in range(self.audio.get_device_count()):\n",
    "                device_info = self.audio.get_device_info_by_index(i)\n",
    "                if device_info['maxInputChannels'] > 0:\n",
    "                    print(f\"Device {i}: {device_info['name']}\")\n",
    "                    print(f\"  Input channels: {device_info['maxInputChannels']}\")\n",
    "                    print(f\"  Sample rate: {int(device_info['defaultSampleRate'])}\")\n",
    "                    print()\n",
    "\n",
    "            # 기본 입력 장치 찾기\n",
    "            self.input_device_index = self.audio.get_default_input_device_info()['index']\n",
    "            print(f\"선택된 입력 장치: {self.audio.get_device_info_by_index(self.input_device_index)['name']}\")\n",
    "\n",
    "            # 테스트 녹음\n",
    "            print(\"\\n입력 장치 테스트 중...\")\n",
    "            stream = self.audio.open(\n",
    "                format=self.format,\n",
    "                channels=self.channels,\n",
    "                rate=self.samplerate,\n",
    "                input=True,\n",
    "                input_device_index=self.input_device_index,\n",
    "                frames_per_buffer=self.chunk_size\n",
    "            )\n",
    "\n",
    "            data = stream.read(self.chunk_size)\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "\n",
    "            print(\"입력 장치 테스트 성공\")\n",
    "            print(\"오디오 장치 초기화 완료\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"오디오 장치 초기화 중 오류 발생: {str(e)}\")\n",
    "            print(\"상세 오류 정보:\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            raise\n",
    "        \n",
    "    def split_into_sentences(self, text):\n",
    "        \"\"\"텍스트를 줄바꿈 단위로 분할\"\"\"\n",
    "        # 줄바꿈으로 문장 분리 및 빈 줄 제거\n",
    "        return [sent.strip() for sent in text.split('\\n') if sent.strip()]\n",
    "\n",
    "    def record_audio(self):\n",
    "        \"\"\"엔터 키로 제어되는 오디오 녹음\"\"\"\n",
    "        print(\"엔터 키를 눌러 녹음을 시작하세요...\")\n",
    "        keyboard.wait('enter')\n",
    "        print(\"녹음 시작... (엔터 키를 다시 누르면 녹음이 종료됩니다)\")\n",
    "        \n",
    "        stream = self.audio.open(\n",
    "            format=self.format,\n",
    "            channels=self.channels,\n",
    "            rate=self.samplerate,\n",
    "            input=True,\n",
    "            input_device_index=self.input_device_index,\n",
    "            frames_per_buffer=self.chunk_size\n",
    "        )\n",
    "\n",
    "        frames = []\n",
    "        self.is_recording = True\n",
    "\n",
    "        while self.is_recording:\n",
    "            if keyboard.is_pressed('enter'):\n",
    "                self.is_recording = False\n",
    "                break\n",
    "            data = stream.read(self.chunk_size)\n",
    "            frames.append(data)\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        print(\"녹음 완료\")\n",
    "        \n",
    "        return b''.join(frames)\n",
    "\n",
    "    def save_audio(self, audio_data, filename=\"temp_audio.wav\"):\n",
    "        \"\"\"오디오 데이터를 파일로 저장\"\"\"\n",
    "        with wave.open(filename, 'wb') as wf:\n",
    "            wf.setnchannels(self.channels)\n",
    "            wf.setsampwidth(self.audio.get_sample_size(self.format))\n",
    "            wf.setframerate(self.samplerate)\n",
    "            wf.writeframes(audio_data)\n",
    "        return filename\n",
    "\n",
    "    def play_audio(self, filename):\n",
    "        \"\"\"오디오 파일 재생\"\"\"\n",
    "        try:\n",
    "            data, fs = sf.read(filename)\n",
    "            stream = self.audio.open(\n",
    "                format=self.audio.get_format_from_width(2),\n",
    "                channels=1,\n",
    "                rate=fs,\n",
    "                output=True\n",
    "            )\n",
    "\n",
    "            # Float32 to Int16 변환\n",
    "            audio_data = (data * 32767).astype(np.int16)\n",
    "\n",
    "            # 청크 단위로 재생\n",
    "            chunk_size = 1024\n",
    "            for i in range(0, len(audio_data), chunk_size):\n",
    "                chunk = audio_data[i:i + chunk_size]\n",
    "                stream.write(chunk.tobytes())\n",
    "\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"오디오 재생 중 오류 발생: {e}\")\n",
    "            print(\"상세 오류 정보:\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def transcribe_audio(self, audio_file):\n",
    "        \"\"\"Whisper를 사용하여 음성을 텍스트로 변환\"\"\"\n",
    "        try:\n",
    "            result = self.whisper_model.transcribe(\n",
    "                audio_file,\n",
    "                language=\"ko\",\n",
    "                task=\"transcribe\"\n",
    "            )\n",
    "            return result[\"text\"].strip()\n",
    "        except Exception as e:\n",
    "            print(f\"음성 인식 오류: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_ai_response(self, text):\n",
    "        \"\"\"OpenAI API를 사용하여 응답 생성\"\"\"\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"당신은 도움이 되는 한국어 AI 어시스턴트입니다. 답변을 할 때 영어 및 한국어 단어의 경우에는 한국어로 소리나는 대로 답변해주세요. ex) API = 에이피아이. 그리고 1개의 문장이 끝나면 반드시 줄바꿈을 사용하세요. 이건 매우 중요합니다.\"},\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ]\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"AI 응답 생성 오류: {e}\")\n",
    "            return \"죄송합니다. 응답을 생성하는 중에 오류가 발생했습니다.\"\n",
    "\n",
    "\n",
    "\n",
    "    async def process_tts(self, text, index, total):\n",
    "        \"\"\"TTS 처리 및 재생을 위한 비동기 함수\"\"\"\n",
    "        try:\n",
    "            self.is_speaking = True\n",
    "            output_path = f'temp_response_{index}.wav'\n",
    "            \n",
    "            # TTS API 호출\n",
    "            tts_data = {\n",
    "                \"language\": \"KR\",\n",
    "                \"text\": text,\n",
    "                \"speed\": 1.2\n",
    "            }\n",
    "            \n",
    "            # TTS API 호출을 ThreadPool에서 실행\n",
    "            loop = asyncio.get_event_loop()\n",
    "            response = await loop.run_in_executor(\n",
    "                self.executor,\n",
    "                lambda: requests.post(self.tts_url, headers=self.tts_headers, json=tts_data)\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                # 응답 데이터를 파일로 저장\n",
    "                with open(output_path, \"wb\") as f:\n",
    "                    f.write(response.content)\n",
    "                \n",
    "                print(f\"AI 응답 ({index+1}/{total}): {text}\")\n",
    "                \n",
    "                # 오디오 재생을 ThreadPool에서 실행\n",
    "                await loop.run_in_executor(self.executor, self.play_audio, output_path)\n",
    "                os.remove(output_path)\n",
    "            else:\n",
    "                print(f\"TTS API 오류: {response.status_code}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"음성 합성 오류: {e}\")\n",
    "        finally:\n",
    "            self.is_speaking = False\n",
    "\n",
    "    async def speak_async(self, text):\n",
    "        \"\"\"문장 단위로 분할하여 비동기적으로 TTS 처리\"\"\"\n",
    "        sentences = self.split_into_sentences(text)\n",
    "        total_sentences = len(sentences)\n",
    "        \n",
    "        if total_sentences > 3:\n",
    "            print(f\"\\n긴 응답을 처리합니다. 총 {total_sentences}개의 문장이 순차적으로 재생됩니다.\")\n",
    "        \n",
    "        for i, sentence in enumerate(sentences):\n",
    "            await self.process_tts(sentence, i, total_sentences)\n",
    "            await asyncio.sleep(0.2)  # 문장 사이 약간의 간격\n",
    "\n",
    "    def speak(self, text):\n",
    "        \"\"\"동기 방식의 speak 메소드\"\"\"\n",
    "        asyncio.run(self.speak_async(text))\n",
    "\n",
    "\n",
    "    async def run_async(self):\n",
    "        \"\"\"비동기 실행 루프\"\"\"\n",
    "        print(\"\\nAI 어시스턴트가 시작되었습니다.\")\n",
    "        print(\"대화를 시작하려면 엔터 키를 눌러주세요.\")\n",
    "        \n",
    "        # 시작 멘트 재생\n",
    "        await self.speak_async(self.greeting_message)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                if self.is_speaking:\n",
    "                    await asyncio.sleep(0.1)\n",
    "                    continue\n",
    "\n",
    "                # 녹음은 동기 방식으로 유지\n",
    "                audio_data = self.record_audio()\n",
    "                audio_file = self.save_audio(audio_data)\n",
    "\n",
    "                text = self.transcribe_audio(audio_file)\n",
    "                if text:\n",
    "                    print(f\"\\n인식된 텍스트: {text}\")\n",
    "                    response = self.get_ai_response(text)\n",
    "                    await self.speak_async(response)\n",
    "                    await asyncio.sleep(0.2)\n",
    "\n",
    "                os.remove(audio_file)\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n프로그램을 종료합니다.\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"실행 중 오류 발생: {str(e)}\")\n",
    "                print(\"상세 오류 정보:\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "            \n",
    "    def run(self):\n",
    "        \"\"\"메인 실행 함수\"\"\"\n",
    "        asyncio.run(self.run_async())\n",
    "        \n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"클래스 소멸자\"\"\"\n",
    "        if hasattr(self, 'executor'):\n",
    "            self.executor.shutdown()\n",
    "        if hasattr(self, 'audio'):\n",
    "            self.audio.terminate()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"프로그램 시작...\")\n",
    "        assistant = SmartAssistant()\n",
    "        assistant.run()\n",
    "    except Exception as e:\n",
    "        print(f\"프로그램 실행 중 치명적 오류 발생: {str(e)}\")\n",
    "        print(\"상세 오류 정보:\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
